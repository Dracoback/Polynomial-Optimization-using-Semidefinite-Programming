% !TEX root = mythesis.tex

\chapter{Introduction}

Optimization is a topic in mathematics that has many practical uses. It is always helpful to know what the best possible outcome for a given problem may be. However, optimization is a topic that is barely discussed in the undergraduate curriculum. There is a brief discussion of the simplex method for linear programming, but overall the topic of optimization is left off the table. This can be attributed in part to the lack of ability to perform most optimization algorithms by hand. It can also be attributed to the amount of mathematical insight required to comprehend more complicated optimization problems.

In this thesis, we will explore semidefinite programming, a branch of conic programming that will allow us to tackle some polynomial optimization problems. Our goal is to solve the problem 
\begin{equation} 
	\textnormal{Maximize } \gamma \quad \textnormal{subject to } \quad p(x) - \gamma \quad \textnormal{is nonnegative}.
\end{equation}
for some polynomial $p(x)$. We will show how we can approximate (sometimes exactly) this problem with sums of squares, and we will show how those sums of squares can be written as a semidefinite program. We will also show how we can adapt our problem formulation given multiple variables and constraints. 

In Chapter 2, we will introduce the concept of a dual problem and discuss how it is used to create conditions for optimality. Chapter 2 will also discuss linear, conic, and semidefinite programming, and show the dual problems for these. In Chapter 3, we will discuss nonnegative polynomials and their relation to sum of squares polynomials. We will then show how sum of square polynomials can be rewritten as a semidefinite matrix, and use that to create polynomial optimization problems using sum of squares polynomials and semidefinite programming. We will then wrap up Chapter 3 with some numerical tests of our solvers, as well as an application. 